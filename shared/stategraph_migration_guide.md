# ğŸ“˜ LangGraph ReAct Agent ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

> `create_react_agent`ì—ì„œ ì»¤ìŠ¤í…€ StateGraphë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ê¸°

**ëŒ€ìƒ ë…ì**: ì‹ ì… ê°œë°œì
**ë‚œì´ë„**: ì¤‘ê¸‰
**ì†Œìš” ì‹œê°„**: 30-60ë¶„
**ëª©í‘œ**: create_react_agentë¥¼ ìˆœìˆ˜ LangGraph StateGraphë¡œ êµì²´í•˜ì—¬ ì™„ì „í•œ ì œì–´ê¶Œ í™•ë³´

---

## ğŸ“‹ ëª©ì°¨

1. [ì™œ ë³€ê²½í•´ì•¼ í•˜ë‚˜ìš”?](#1-ì™œ-ë³€ê²½í•´ì•¼-í•˜ë‚˜ìš”)
2. [ì‚¬ì „ ì¤€ë¹„](#2-ì‚¬ì „-ì¤€ë¹„)
3. [ë§ˆì´ê·¸ë ˆì´ì…˜ ë‹¨ê³„](#3-ë§ˆì´ê·¸ë ˆì´ì…˜-ë‹¨ê³„)
4. [í…ŒìŠ¤íŠ¸ ë° ê²€ì¦](#4-í…ŒìŠ¤íŠ¸-ë°-ê²€ì¦)
5. [ë¬¸ì œ í•´ê²°](#5-ë¬¸ì œ-í•´ê²°)
6. [ì¶”ê°€ í•™ìŠµ ìë£Œ](#6-ì¶”ê°€-í•™ìŠµ-ìë£Œ)

---

## 1. ì™œ ë³€ê²½í•´ì•¼ í•˜ë‚˜ìš”?

### ğŸ¯ ë³€ê²½ ë™ê¸°

**create_react_agentì˜ í•œê³„:**
```python
# ğŸ”’ Black Box: ë‚´ë¶€ ë¡œì§ ìˆ˜ì • ë¶ˆê°€
return create_react_agent(
    prompt=system_prompt,
    model=model,
    tools=tools,
    config_schema=ConfigSchema,
)
```

**StateGraphì˜ ì¥ì :**
- âœ… **ì™„ì „í•œ ì œì–´**: ëª¨ë“  ë…¸ë“œì™€ ì—£ì§€ë¥¼ ì§ì ‘ ì •ì˜
- âœ… **ì»¤ìŠ¤í„°ë§ˆì´ì§•**: ê²€ì¦, ë¡œê¹…, í•„í„°ë§ ë…¸ë“œ ì¶”ê°€ ê°€ëŠ¥
- âœ… **ë””ë²„ê¹…**: ê° ë‹¨ê³„ë¥¼ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
- âœ… **í™•ì¥ì„±**: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° êµ¬í˜„ ê°€ëŠ¥
- âœ… **ìµœì í™”**: ë©”ì‹œì§€ íŠ¸ë¦¬ë°ìœ¼ë¡œ ë¹„ìš© ì ˆê° ë° ì„±ëŠ¥ í–¥ìƒ

### ğŸ“Š ë¹„êµí‘œ

| ê¸°ëŠ¥ | create_react_agent | StateGraph |
|------|-------------------|------------|
| êµ¬í˜„ ë‚œì´ë„ | ì‰¬ì›€ (5ë¶„) | ì¤‘ê°„ (30ë¶„) |
| ì»¤ìŠ¤í„°ë§ˆì´ì§• | ì œí•œì  | ë¬´ì œí•œ |
| ë””ë²„ê¹… | ì–´ë ¤ì›€ | ì‰¬ì›€ |
| ë…¸ë“œ ì¶”ê°€ | ë¶ˆê°€ëŠ¥ | ê°€ëŠ¥ |
| í•™ìŠµ ê°€ì¹˜ | ë‚®ìŒ | ë†’ìŒ |

---

## 2. ì‚¬ì „ ì¤€ë¹„

### âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Python 3.11+ ì„¤ì¹˜ í™•ì¸
- [ ] í”„ë¡œì íŠ¸ ë°±ì—… ì™„ë£Œ
- [ ] Git ì»¤ë°‹ ë˜ëŠ” ë¸Œëœì¹˜ ìƒì„±
- [ ] ê¸°ì¡´ ì½”ë“œ ì´í•´ (agent.py ì½ê¸°)
- [ ] LangGraph ê¸°ë³¸ ê°œë… ìˆ™ì§€

### ğŸ” ê¸°ì¡´ ì½”ë“œ ìœ„ì¹˜ í™•ì¸

```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ
cd tools_agent
cat agent.py | grep -A 5 "create_react_agent"
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```python
return create_react_agent(
    prompt=cfg.system_prompt + UNEDITABLE_SYSTEM_PROMPT,
    model=model,
    tools=tools,
    config_schema=GraphConfigPydantic,
)
```

### ğŸ“¦ í•„ìš”í•œ ê°œë…

**1. StateGraphë€?**
- LangGraphì˜ í•µì‹¬ í´ë˜ìŠ¤
- ë…¸ë“œ(í•¨ìˆ˜)ì™€ ì—£ì§€(ì—°ê²°)ë¡œ êµ¬ì„±ëœ ê·¸ë˜í”„
- ìƒíƒœ(State)ë¥¼ ë…¸ë“œ ê°„ì— ì „ë‹¬

**2. ReAct íŒ¨í„´ì´ë€?**
- **Re**asoning + **Act**ing
- LLMì´ ìƒê°í•˜ê³ (reasoning) â†’ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê³ (acting) â†’ ê²°ê³¼ë¥¼ ë³´ê³  â†’ ë°˜ë³µ

**3. í•µì‹¬ ì»´í¬ë„ŒíŠ¸:**
```
State â†’ Node â†’ Edge â†’ Router â†’ Compile
  â†“       â†“      â†“       â†“        â†“
 ìƒíƒœ   í•¨ìˆ˜   ì—°ê²°   ì¡°ê±´ë¶„ê¸°   ì‹¤í–‰
```

---

## 3. ë§ˆì´ê·¸ë ˆì´ì…˜ ë‹¨ê³„

### ğŸ“ ì „ì²´ íë¦„

```
Step 1: Import ì¶”ê°€
  â†“
Step 2: AgentState ì •ì˜
  â†“
Step 3: Router í•¨ìˆ˜ ì‘ì„±
  â†“
Step 4: StateGraph êµ¬í˜„
  â†“
Step 5: ê¸°ì¡´ ì½”ë“œ êµì²´
```

---

### Step 1: Import ë¬¸ ì¶”ê°€

**ìœ„ì¹˜**: `tools_agent/agent.py` íŒŒì¼ ìƒë‹¨

**ê¸°ì¡´ ì½”ë“œ:**
```python
import os
from langchain_core.runnables import RunnableConfig
from typing import Optional, List
from pydantic import BaseModel, Field
from langgraph.prebuilt import create_react_agent  # â† ì´ê²ƒì„ ë³€ê²½í•  ê²ƒ
from tools_agent.utils.tools import create_rag_tool
# ... ê¸°íƒ€ imports
```

**ë³€ê²½ í›„:**
```python
import os
from langchain_core.runnables import RunnableConfig
from typing import Optional, List, Annotated, Sequence  # â† ì¶”ê°€
from pydantic import BaseModel, Field
from typing_extensions import TypedDict  # â† ì¶”ê°€
from langchain_core.messages import BaseMessage, SystemMessage, trim_messages  # â† ì¶”ê°€
from langgraph.graph import StateGraph, START, END  # â† ì¶”ê°€
from langgraph.graph.message import add_messages  # â† ì¶”ê°€
from langgraph.prebuilt import ToolNode  # â† ë³€ê²½
from tools_agent.utils.tools import create_rag_tool
# ... ê¸°íƒ€ imports
```

**ğŸ’¡ ì„¤ëª…:**
- `Annotated, Sequence`: íƒ€ì… íŒíŠ¸ìš©
- `TypedDict`: State í´ë˜ìŠ¤ ì •ì˜ìš©
- `BaseMessage, SystemMessage, trim_messages`: ë©”ì‹œì§€ íƒ€ì… ë° íŠ¸ë¦¬ë° í•¨ìˆ˜
- `StateGraph, START, END`: ê·¸ë˜í”„ êµ¬ì„± ìš”ì†Œ
- `add_messages`: ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ reducer
- `ToolNode`: ë„êµ¬ ì‹¤í–‰ ë…¸ë“œ

---

### Step 2: AgentState í´ë˜ìŠ¤ ì •ì˜

**ìœ„ì¹˜**: `UNEDITABLE_SYSTEM_PROMPT` ì •ì˜ ë°”ë¡œ ì•„ë˜

**ì¶”ê°€í•  ì½”ë“œ:**
```python
# UNEDITABLE_SYSTEM_PROMPT = "..."
# DEFAULT_SYSTEM_PROMPT = "..."

# â† ì—¬ê¸°ì— ì¶”ê°€
# Define AgentState for StateGraph
class AgentState(TypedDict):
    """State for the ReAct agent graph."""
    messages: Annotated[Sequence[BaseMessage], add_messages]
```

**ğŸ’¡ ì„¤ëª…:**

**AgentStateë€?**
- ê·¸ë˜í”„ì˜ "ìƒíƒœ"ë¥¼ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤
- ë…¸ë“œ ê°„ì— ì „ë‹¬ë˜ëŠ” ë°ì´í„° êµ¬ì¡°

**messages í•„ë“œ:**
- `Sequence[BaseMessage]`: ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ íƒ€ì…
- `add_messages`: ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ëŠ” reducer í•¨ìˆ˜
- ReducerëŠ” ìƒˆ ë©”ì‹œì§€ë¥¼ ê¸°ì¡´ ë¦¬ìŠ¤íŠ¸ì— ë³‘í•©í•˜ëŠ” ë°©ë²•ì„ ì •ì˜

**ì˜ˆì œ:**
```python
# State ì´ˆê¸°ê°’
{"messages": [HumanMessage(content="ì•ˆë…•")]}

# Nodeì—ì„œ ë°˜í™˜
{"messages": [AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”")]}

# Reducer ì ìš© í›„ ê²°ê³¼
{"messages": [
    HumanMessage(content="ì•ˆë…•"),
    AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”")
]}
```

---

### Step 3: Router í•¨ìˆ˜ ì‘ì„±

**ìœ„ì¹˜**: `get_api_key_for_model` í•¨ìˆ˜ ë°”ë¡œ ì•„ë˜

**ì¶”ê°€í•  ì½”ë“œ:**
```python
def get_api_key_for_model(model_name: str, config: RunnableConfig):
    # ... ê¸°ì¡´ ì½”ë“œ ...
    return os.getenv(key_name)


# â† ì—¬ê¸°ì— ì¶”ê°€
def should_continue(state: AgentState):
    """Router function to decide whether to continue to tools or end."""
    messages = state["messages"]
    last_message = messages[-1]

    # Check if the last message has tool calls
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tools"

    # Otherwise end the conversation
    return END
```

**ğŸ’¡ ì„¤ëª…:**

**Router í•¨ìˆ˜ë€?**
- ì¡°ê±´ë¶€ ì—£ì§€(Conditional Edge)ì—ì„œ ì‚¬ìš©
- Stateë¥¼ ë°›ì•„ì„œ ë‹¤ìŒ ë…¸ë“œ ì´ë¦„ì„ ë°˜í™˜
- ê·¸ë˜í”„ì˜ "ë¶„ê¸°ì " ì—­í• 

**ë¡œì§ ë¶„ì„:**
```python
# 1. ìƒíƒœì—ì„œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
messages = state["messages"]

# 2. ë§ˆì§€ë§‰ ë©”ì‹œì§€ í™•ì¸
last_message = messages[-1]

# 3. tool_calls ì†ì„± ì²´í¬
if hasattr(last_message, "tool_calls") and last_message.tool_calls:
    # LLMì´ ë„êµ¬ í˜¸ì¶œì„ ìš”ì²­í•¨ â†’ "tools" ë…¸ë“œë¡œ
    return "tools"

# 4. tool_calls ì—†ìŒ â†’ ëŒ€í™” ì¢…ë£Œ
return END
```

**ì˜ˆì œ ì‹œë‚˜ë¦¬ì˜¤:**

**ì‹œë‚˜ë¦¬ì˜¤ 1: ë„êµ¬ í˜¸ì¶œ í•„ìš”**
```python
last_message = AIMessage(
    content="ê³„ì‚°í•˜ê² ìŠµë‹ˆë‹¤",
    tool_calls=[{"name": "calculator", "args": {"a": 2, "b": 3}}]
)
# â†’ return "tools"
```

**ì‹œë‚˜ë¦¬ì˜¤ 2: ìµœì¢… ë‹µë³€**
```python
last_message = AIMessage(content="2 + 3 = 5ì…ë‹ˆë‹¤")
# â†’ return END
```

---

### Step 4: StateGraph êµ¬í˜„ (í•µì‹¬!)

**ìœ„ì¹˜**: `graph` í•¨ìˆ˜ ë‚´ë¶€, `model` ì´ˆê¸°í™” ì´í›„

**ê¸°ì¡´ ì½”ë“œ (ì‚­ì œí•  ë¶€ë¶„):**
```python
async def graph(config: RunnableConfig):
    # ... RAG ë„êµ¬ ë¡œë”© ...
    # ... MCP ë„êµ¬ ë¡œë”© ...

    model = init_chat_model(
        cfg.model_name,
        temperature=cfg.temperature,
        max_tokens=cfg.max_tokens,
        api_key=get_api_key_for_model(cfg.model_name, config) or "No token found"
    )

    # âŒ ì´ ë¶€ë¶„ì„ ì‚­ì œ
    return create_react_agent(
        prompt=cfg.system_prompt + UNEDITABLE_SYSTEM_PROMPT,
        model=model,
        tools=tools,
        config_schema=GraphConfigPydantic,
    )
```

**ìƒˆë¡œìš´ ì½”ë“œ (ì¶”ê°€í•  ë¶€ë¶„):**
```python
async def graph(config: RunnableConfig):
    # ... RAG ë„êµ¬ ë¡œë”© (ë³€ê²½ ì—†ìŒ) ...
    # ... MCP ë„êµ¬ ë¡œë”© (ë³€ê²½ ì—†ìŒ) ...

    model = init_chat_model(
        cfg.model_name,
        temperature=cfg.temperature,
        max_tokens=cfg.max_tokens,
        api_key=get_api_key_for_model(cfg.model_name, config) or "No token found"
    )

    # âœ… ì—¬ê¸°ë¶€í„° ìƒˆë¡œìš´ ì½”ë“œ

    # 1ï¸âƒ£ Modelì— tools ë°”ì¸ë”©
    model_with_tools = model.bind_tools(tools) if tools else model

    # 2ï¸âƒ£ Agent node ì •ì˜
    async def agent_node(state: AgentState, config: RunnableConfig):
        """Agent node that calls the LLM with system prompt."""
        # Get system prompt from config
        cfg = GraphConfigPydantic(**config.get("configurable", {}))
        system_prompt = cfg.system_prompt + UNEDITABLE_SYSTEM_PROMPT

        # Trim conversation history to prevent context overflow
        trimmed_messages = trim_messages(
            state["messages"],
            max_tokens=10000,
            strategy="last",
            token_counter=len,
        )

        # Prepend system message to conversation
        messages = [SystemMessage(content=system_prompt)] + trimmed_messages

        # Call the model
        response = await model_with_tools.ainvoke(messages, config)

        # Return the response to add to state
        return {"messages": [response]}

    # 3ï¸âƒ£ Tools node ìƒì„±
    tools_node = ToolNode(tools) if tools else None

    # 4ï¸âƒ£ StateGraph ë¹Œë“œ
    workflow = StateGraph(AgentState, config_schema=GraphConfigPydantic)

    # 5ï¸âƒ£ ë…¸ë“œ ì¶”ê°€
    workflow.add_node("agent", agent_node)
    if tools_node:
        workflow.add_node("tools", tools_node)

    # 6ï¸âƒ£ ì—£ì§€ ì¶”ê°€
    workflow.add_edge(START, "agent")

    if tools_node:
        # Conditional edge from agent: either go to tools or end
        workflow.add_conditional_edges(
            "agent",
            should_continue,
            {
                "tools": "tools",
                END: END,
            },
        )
        # Always return from tools back to agent
        workflow.add_edge("tools", "agent")
    else:
        # If no tools, just end after agent
        workflow.add_edge("agent", END)

    # 7ï¸âƒ£ ì»´íŒŒì¼ ë° ë°˜í™˜
    return workflow.compile()
```

---

### ğŸ“š Step 4 ìƒì„¸ ì„¤ëª…

#### 1ï¸âƒ£ Modelì— tools ë°”ì¸ë”©

```python
model_with_tools = model.bind_tools(tools) if tools else model
```

**ì™œ í•„ìš”í•œê°€?**
- LLMì´ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ ì•Œì•„ì•¼ í•¨
- `bind_tools()`ëŠ” ëª¨ë¸ì— ë„êµ¬ ì •ë³´ë¥¼ ì¶”ê°€
- ë„êµ¬ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ëª¨ë¸ ì‚¬ìš©

**ì‘ë™ ë°©ì‹:**
```python
# ë„êµ¬ê°€ ìˆì„ ë•Œ
tools = [calculator_tool, search_tool]
model_with_tools = model.bind_tools(tools)
# â†’ LLMì´ ì´ ë‘ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŒì„ ì¸ì§€

# ë„êµ¬ê°€ ì—†ì„ ë•Œ
tools = []
model_with_tools = model  # ê·¸ëƒ¥ ì›ë³¸ ëª¨ë¸
```

#### 2ï¸âƒ£ Agent node ì •ì˜

```python
async def agent_node(state: AgentState, config: RunnableConfig):
    """Agent node that calls the LLM with system prompt."""
    # A. Configì—ì„œ system prompt ì¶”ì¶œ
    cfg = GraphConfigPydantic(**config.get("configurable", {}))
    system_prompt = cfg.system_prompt + UNEDITABLE_SYSTEM_PROMPT

    # B. ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ íŠ¸ë¦¬ë° (ì»¨í…ìŠ¤íŠ¸ ì˜¤ë²„í”Œë¡œìš° ë°©ì§€)
    trimmed_messages = trim_messages(
        state["messages"],
        max_tokens=10000,
        strategy="last",
        token_counter=len,
    )

    # C. SystemMessageë¥¼ ëŒ€í™” ë§¨ ì•ì— ì¶”ê°€
    messages = [SystemMessage(content=system_prompt)] + trimmed_messages

    # D. LLM í˜¸ì¶œ
    response = await model_with_tools.ainvoke(messages, config)

    # E. ì‘ë‹µì„ Stateì— ì¶”ê°€í•˜ê¸° ìœ„í•´ ë°˜í™˜
    return {"messages": [response]}
```

**ë‹¨ê³„ë³„ ë¶„ì„:**

**A. System prompt ì¶”ì¶œ**
```python
cfg = GraphConfigPydantic(**config.get("configurable", {}))
system_prompt = cfg.system_prompt + UNEDITABLE_SYSTEM_PROMPT
```
- Configì—ì„œ ì‚¬ìš©ì ì •ì˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
- í•„ìˆ˜ í”„ë¡¬í”„íŠ¸(UNEDITABLE_SYSTEM_PROMPT) ì¶”ê°€

**B. ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ íŠ¸ë¦¬ë° âš ï¸ ì¤‘ìš”!**
```python
trimmed_messages = trim_messages(
    state["messages"],
    max_tokens=10000,
    strategy="last",
    token_counter=len,
)
```

**ì™œ í•„ìš”í•œê°€?**
- ê¸´ ëŒ€í™”ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì´ˆê³¼ ë°©ì§€
- API ë¹„ìš© ìµœì í™” (í† í° ì‚¬ìš©ëŸ‰ ì œì–´)
- ì‘ë‹µ ì†ë„ ê°œì„  (ì²˜ë¦¬í•  ë°ì´í„° ê°ì†Œ)

**ë™ì‘ ë°©ì‹:**
- `max_tokens=10000`: ìµœëŒ€ 10K í† í°ë§Œ ìœ ì§€
- `strategy="last"`: ìµœì‹  ë©”ì‹œì§€ë¶€í„° ìœ ì§€
- `token_counter=len`: ê°„ë‹¨í•œ ê·¼ì‚¬ì¹˜ ì‚¬ìš© (1 char â‰ˆ 1 token)

**ì˜ˆì œ:**
```python
# 100í„´ ëŒ€í™” (50K í† í°)
state["messages"] = [...100 messages...]

# trim_messages ì ìš© í›„
trimmed_messages = [...ìµœê·¼ 20ê°œ messages...] # ~10K í† í°

# ê²°ê³¼: ë¹„ìš© 80% ì ˆê°, ì†ë„ 5ë°° í–¥ìƒ
```

**C. ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±**
```python
messages = [SystemMessage(content=system_prompt)] + trimmed_messages
```

ì˜ˆì œ:
```python
# trimmed_messages
[
    HumanMessage(content="2 + 3ì€?"),
]

# ë³€í™˜ í›„
[
    SystemMessage(content="You are a helpful assistant..."),  # â† ì¶”ê°€
    HumanMessage(content="2 + 3ì€?"),
]
```

**D. LLM í˜¸ì¶œ**
```python
response = await model_with_tools.ainvoke(messages, config)
```
- ë¹„ë™ê¸°ë¡œ LLM í˜¸ì¶œ
- ê²°ê³¼: AIMessage ê°ì²´

**E. ì‘ë‹µ ë°˜í™˜**
```python
return {"messages": [response]}
```
- Dictionary í˜•íƒœë¡œ ë°˜í™˜
- `add_messages` reducerê°€ ìë™ìœ¼ë¡œ ë³‘í•©

#### 3ï¸âƒ£ Tools node ìƒì„±

```python
tools_node = ToolNode(tools) if tools else None
```

**ToolNodeë€?**
- LangChain ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ëŠ” í”„ë¦¬ë¹ŒíŠ¸ ë…¸ë“œ
- tool_callsë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬
- ê²°ê³¼ë¥¼ ToolMessageë¡œ ë°˜í™˜

**ì‘ë™ ì˜ˆì‹œ:**
```python
# Input state
{
    "messages": [
        HumanMessage("2 + 3ì€?"),
        AIMessage(tool_calls=[{"name": "calculator", "args": {"a": 2, "b": 3}}])
    ]
}

# ToolNode ì‹¤í–‰ â†’

# Output
{
    "messages": [
        ToolMessage(content="5", tool_call_id="...")
    ]
}
```

#### 4ï¸âƒ£ StateGraph ë¹Œë“œ

```python
workflow = StateGraph(AgentState, config_schema=GraphConfigPydantic)
```

**ë§¤ê°œë³€ìˆ˜:**
- `AgentState`: ìƒíƒœ íƒ€ì… ì§€ì •
- `config_schema`: OAP UI í†µí•©ì„ ìœ„í•œ ì„¤ì • ìŠ¤í‚¤ë§ˆ

#### 5ï¸âƒ£ ë…¸ë“œ ì¶”ê°€

```python
workflow.add_node("agent", agent_node)
if tools_node:
    workflow.add_node("tools", tools_node)
```

**ë…¸ë“œ ë“±ë¡:**
- `"agent"`: ë…¸ë“œ ì´ë¦„ (ë¬¸ìì—´)
- `agent_node`: ì‹¤í–‰í•  í•¨ìˆ˜

#### 6ï¸âƒ£ ì—£ì§€ ì¶”ê°€ (ê·¸ë˜í”„ ì—°ê²°)

**ê¸°ë³¸ ì—£ì§€:**
```python
workflow.add_edge(START, "agent")
```
- ê·¸ë˜í”„ ì‹œì‘ â†’ agent ë…¸ë“œ

**ì¡°ê±´ë¶€ ì—£ì§€ (ë„êµ¬ê°€ ìˆì„ ë•Œ):**
```python
workflow.add_conditional_edges(
    "agent",           # ì¶œë°œ ë…¸ë“œ
    should_continue,   # Router í•¨ìˆ˜
    {
        "tools": "tools",  # Routerê°€ "tools" ë°˜í™˜ â†’ tools ë…¸ë“œ
        END: END,          # Routerê°€ END ë°˜í™˜ â†’ ì¢…ë£Œ
    },
)
```

**ëŒì•„ì˜¤ëŠ” ì—£ì§€:**
```python
workflow.add_edge("tools", "agent")
```
- tools ë…¸ë“œ â†’ agent ë…¸ë“œ (í•­ìƒ)

**ê·¸ë˜í”„ ì‹œê°í™”:**
```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
START â”€â”€â†’â”‚  agent  â”‚
         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
              â”‚
         [tool_calls?]
         â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
       Yesâ”‚        â”‚No
         â†“         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”    END
    â”‚ tools â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”˜
        â”‚
        â””â”€â”€â†’ (back to agent)
```

**ë„êµ¬ê°€ ì—†ì„ ë•Œ:**
```python
workflow.add_edge("agent", END)
```
- agent â†’ ë°”ë¡œ ì¢…ë£Œ

#### 7ï¸âƒ£ ì»´íŒŒì¼ ë° ë°˜í™˜

```python
return workflow.compile()
```

**compile()ì´ í•˜ëŠ” ì¼:**
- ê·¸ë˜í”„ ê²€ì¦ (ìˆœí™˜ ì°¸ì¡°, ì—°ê²° ì˜¤ë¥˜ ì²´í¬)
- ì‹¤í–‰ ê°€ëŠ¥í•œ ê°ì²´ë¡œ ë³€í™˜
- ìµœì í™” ìˆ˜í–‰

---

### Step 5: ì™„ë£Œ í™•ì¸

**ë³€ê²½ ì‚¬í•­ ìš”ì•½:**
1. âœ… Import ì¶”ê°€ (7ê°œ)
2. âœ… AgentState í´ë˜ìŠ¤ ì •ì˜
3. âœ… should_continue í•¨ìˆ˜ ì¶”ê°€
4. âœ… StateGraph êµ¬í˜„ (50ì¤„)
5. âœ… create_react_agent í˜¸ì¶œ ì œê±°

**íŒŒì¼ ì €ì¥:**
```bash
# agent.py ì €ì¥ í™•ì¸
git diff tools_agent/agent.py
```

---

## 4. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

### ğŸ§ª í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

#### Level 1: êµ¬ë¬¸ ê²€ì‚¬

```bash
# Python ë¬¸ë²• ì˜¤ë¥˜ í™•ì¸
cd /mnt/e/MyProject2/oap-mcp
source .venv/bin/activate
python -c "import tools_agent.agent"
```

**ì„±ê³µ ì‹œ:** ì•„ë¬´ ì¶œë ¥ ì—†ìŒ
**ì‹¤íŒ¨ ì‹œ:** SyntaxError í‘œì‹œ â†’ í•´ë‹¹ ì¤„ ìˆ˜ì •

#### Level 2: ì„œë²„ ì‹œì‘

```bash
uv run langgraph dev --no-browser
```

**ì˜ˆìƒ ì¶œë ¥:**
```
Starting server on http://localhost:2024
Graph loaded successfully: agent
```

**ì‹¤íŒ¨ ì‹œ ì²´í¬:**
- [ ] Import ì˜¤ë¥˜ â†’ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸
- [ ] í•¨ìˆ˜ ì •ì˜ ì˜¤ë¥˜ â†’ ë“¤ì—¬ì“°ê¸° í™•ì¸
- [ ] íƒ€ì… ì˜¤ë¥˜ â†’ TypedDict í™•ì¸

#### Level 3: ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

**í…ŒìŠ¤íŠ¸ 1: ê¸°ë³¸ ëŒ€í™” (ë„êµ¬ ì—†ìŒ)**

Request:
```bash
curl -X POST http://localhost:2024/threads/test-1/runs \
  -H "Content-Type: application/json" \
  -d '{
    "assistant_id": "agent",
    "input": {
      "messages": [
        {"role": "human", "content": "ì•ˆë…•í•˜ì„¸ìš”"}
      ]
    },
    "config": {
      "configurable": {
        "model_name": "openai:gpt-4o-mini",
        "system_prompt": "You are a helpful assistant."
      }
    }
  }'
```

**ì˜ˆìƒ ê²°ê³¼:**
- âœ… ì •ìƒ ì‘ë‹µ (AIMessage)
- âœ… ì—ëŸ¬ ì—†ìŒ

**í…ŒìŠ¤íŠ¸ 2: ë„êµ¬ í˜¸ì¶œ**

Request:
```bash
curl -X POST http://localhost:2024/threads/test-2/runs \
  -H "Content-Type: application/json" \
  -d '{
    "assistant_id": "agent",
    "input": {
      "messages": [
        {"role": "human", "content": "2 + 3ì€ ì–¼ë§ˆì¸ê°€ìš”?"}
      ]
    },
    "config": {
      "configurable": {
        "model_name": "openai:gpt-4o-mini",
        "mcp_config": {
          "url": "http://localhost:8000",
          "tools": ["add"],
          "auth_required": false
        }
      }
    }
  }'
```

**ì˜ˆìƒ ê²°ê³¼:**
- âœ… Tool call ë°œìƒ
- âœ… Tools ë…¸ë“œ ì‹¤í–‰
- âœ… ìµœì¢… ë‹µë³€ ë°˜í™˜

#### Level 4: ê·¸ë˜í”„ ì‹œê°í™”

```python
# Python ì¸í„°í”„ë¦¬í„°ì—ì„œ
from tools_agent.agent import graph
from langchain_core.runnables import RunnableConfig

config = RunnableConfig(configurable={})
g = await graph(config)

# ASCII ê·¸ë˜í”„ ì¶œë ¥
print(g.get_graph().draw_ascii())
```

**ì˜ˆìƒ ì¶œë ¥:**
```
           +-----------+
           | __start__ |
           +-----------+
                  *
                  *
                  *
             +-------+
             | agent |
             +-------+
           ***         ***
        ***               **
      **                    **
+-------+                     **
| tools |                   +---------+
+-------+                   | __end__ |
      **                    +---------+
        ***               **
           ***         ***
             +-------+
             | agent |
             +-------+
```

---

### âœ… ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

**ê¸°ëŠ¥ ë™ë“±ì„±:**
- [ ] ê¸°ë³¸ ëŒ€í™” ë™ì‘ (ë„êµ¬ ì—†ìŒ)
- [ ] ë„êµ¬ í˜¸ì¶œ ë™ì‘
- [ ] ë©€í‹°í„´ ëŒ€í™”
- [ ] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì ìš©
- [ ] Config ë³€ê²½ ë°˜ì˜

**ì„±ëŠ¥:**
- [ ] ì‘ë‹µ ì†ë„ ìœ ì‚¬
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ìƒ
- [ ] ì—ëŸ¬ìœ¨ ë™ì¼ ì´í•˜

**í†µí•©:**
- [ ] OAP UI ì •ìƒ ë™ì‘
- [ ] RAG ë„êµ¬ ì •ìƒ ë™ì‘
- [ ] MCP ë„êµ¬ ì •ìƒ ë™ì‘
- [ ] ìŠ¤íŠ¸ë¦¬ë° ì •ìƒ ë™ì‘

---

## 5. ë¬¸ì œ í•´ê²°

### â“ ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜

#### ì˜¤ë¥˜ 1: "NameError: name 'AgentState' is not defined"

**ì›ì¸:** AgentState í´ë˜ìŠ¤ ì •ì˜ë¥¼ ì¶”ê°€í•˜ì§€ ì•ŠìŒ

**í•´ê²°:**
```python
# ì´ ì½”ë“œë¥¼ DEFAULT_SYSTEM_PROMPT ì•„ë˜ì— ì¶”ê°€
class AgentState(TypedDict):
    """State for the ReAct agent graph."""
    messages: Annotated[Sequence[BaseMessage], add_messages]
```

#### ì˜¤ë¥˜ 2: "ImportError: cannot import name 'StateGraph'"

**ì›ì¸:** Import ë¬¸ ëˆ„ë½

**í•´ê²°:**
```python
# íŒŒì¼ ìƒë‹¨ì— ì¶”ê°€
from langgraph.graph import StateGraph, START, END
```

#### ì˜¤ë¥˜ 3: "TypeError: add_conditional_edges() got an unexpected keyword argument"

**ì›ì¸:** ì¡°ê±´ë¶€ ì—£ì§€ ë¬¸ë²• ì˜¤ë¥˜

**í•´ê²°:**
```python
# ì˜¬ë°”ë¥¸ ë¬¸ë²•
workflow.add_conditional_edges(
    "agent",           # source node
    should_continue,   # router function
    {                  # mapping
        "tools": "tools",
        END: END,
    },
)
```

#### ì˜¤ë¥˜ 4: "AttributeError: 'NoneType' object has no attribute 'tool_calls'"

**ì›ì¸:** should_continue í•¨ìˆ˜ì—ì„œ None ì²´í¬ ëˆ„ë½

**í•´ê²°:**
```python
def should_continue(state: AgentState):
    messages = state["messages"]
    if not messages:  # â† ì¶”ê°€
        return END

    last_message = messages[-1]

    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tools"

    return END
```

#### ì˜¤ë¥˜ 5: "Graph has cycles"

**ì›ì¸:** ë¬´í•œ ë£¨í”„ ì—£ì§€ êµ¬ì„±

**í•´ê²°:**
```python
# âŒ ì˜ëª»ëœ ì˜ˆ
workflow.add_edge("agent", "agent")  # ìê¸° ìì‹ ìœ¼ë¡œ

# âœ… ì˜¬ë°”ë¥¸ ì˜ˆ
workflow.add_edge("tools", "agent")  # tools â†’ agent
```

---

### ğŸ› ë””ë²„ê¹… íŒ

**1. ë¡œê·¸ ì¶”ê°€**
```python
async def agent_node(state: AgentState, config: RunnableConfig):
    print(f"[DEBUG] Agent node called with {len(state['messages'])} messages")
    # ... ê¸°ì¡´ ì½”ë“œ ...
    print(f"[DEBUG] Agent response: {response.content[:100]}")
    return {"messages": [response]}
```

**2. State í™•ì¸**
```python
def should_continue(state: AgentState):
    print(f"[DEBUG] State: {state}")
    print(f"[DEBUG] Last message type: {type(state['messages'][-1])}")
    # ... ê¸°ì¡´ ì½”ë“œ ...
```

**3. ê·¸ë˜í”„ êµ¬ì¡° í™•ì¸**
```python
g = await graph(config)
print(g.get_graph().nodes)  # ë…¸ë“œ ëª©ë¡
print(g.get_graph().edges)  # ì—£ì§€ ëª©ë¡
```

---

## 6. ì¶”ê°€ í•™ìŠµ ìë£Œ

### ğŸ“š ê³µì‹ ë¬¸ì„œ

**LangGraph í•µì‹¬ ê°œë…:**
- [StateGraph ê¸°ì´ˆ](https://langchain-ai.github.io/langgraph/concepts/stategraph/)
- [Conditional Edges](https://langchain-ai.github.io/langgraph/concepts/conditional_edges/)
- [ReAct Agent íŒ¨í„´](https://langchain-ai.github.io/langgraph/tutorials/introduction/)

**ì˜ˆì œ ì½”ë“œ:**
- [Custom ReAct êµ¬í˜„](https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/)
- [Multi-agent ì‹œìŠ¤í…œ](https://langchain-ai.github.io/langgraph/tutorials/multi_agent/multi-agent-collaboration/)

### ğŸ“ ë‹¤ìŒ ë‹¨ê³„

**ì´ˆê¸‰ â†’ ì¤‘ê¸‰:**
1. âœ… ì´ ê°€ì´ë“œ ì™„ë£Œ
2. ì»¤ìŠ¤í…€ ë…¸ë“œ ì¶”ê°€ (ë¡œê¹…, ê²€ì¦)
3. Stateì— í•„ë“œ ì¶”ê°€ (metrics, context)
4. ë³µì¡í•œ Router ì‘ì„±

**ì¤‘ê¸‰ â†’ ê³ ê¸‰:**
5. Multi-agent ì‹œìŠ¤í…œ êµ¬í˜„
6. Human-in-the-loop ì¶”ê°€
7. Dynamic tool loading
8. Subgraph í™œìš©

---

## ğŸ“Š ë¶€ë¡: ì „ì²´ ì½”ë“œ ë¹„êµ

### Before (create_react_agent)

```python
# tools_agent/agent.py (ì¼ë¶€)

from langgraph.prebuilt import create_react_agent

async def graph(config: RunnableConfig):
    # ... ë„êµ¬ ë¡œë”© ...

    model = init_chat_model(
        cfg.model_name,
        temperature=cfg.temperature,
        max_tokens=cfg.max_tokens,
        api_key=get_api_key_for_model(cfg.model_name, config) or "No token found"
    )

    return create_react_agent(
        prompt=cfg.system_prompt + UNEDITABLE_SYSTEM_PROMPT,
        model=model,
        tools=tools,
        config_schema=GraphConfigPydantic,
    )
```

**ì´ ì¤„ ìˆ˜:** 5 lines
**ì»¤ìŠ¤í„°ë§ˆì´ì§•:** ì œí•œì 
**ì œì–´:** Black box

---

### After (StateGraph)

```python
# tools_agent/agent.py (ì „ì²´)

# 1. Import ì¶”ê°€
from typing import Annotated, Sequence
from typing_extensions import TypedDict
from langchain_core.messages import BaseMessage, SystemMessage
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode

# 2. AgentState ì •ì˜
class AgentState(TypedDict):
    """State for the ReAct agent graph."""
    messages: Annotated[Sequence[BaseMessage], add_messages]

# 3. Router í•¨ìˆ˜
def should_continue(state: AgentState):
    """Router function to decide whether to continue to tools or end."""
    messages = state["messages"]
    last_message = messages[-1]

    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tools"

    return END

# 4. Graph í•¨ìˆ˜ ìˆ˜ì •
async def graph(config: RunnableConfig):
    # ... ë„êµ¬ ë¡œë”© (ë™ì¼) ...

    model = init_chat_model(
        cfg.model_name,
        temperature=cfg.temperature,
        max_tokens=cfg.max_tokens,
        api_key=get_api_key_for_model(cfg.model_name, config) or "No token found"
    )

    # Modelì— tools ë°”ì¸ë”©
    model_with_tools = model.bind_tools(tools) if tools else model

    # Agent node ì •ì˜
    async def agent_node(state: AgentState, config: RunnableConfig):
        """Agent node that calls the LLM with system prompt."""
        cfg = GraphConfigPydantic(**config.get("configurable", {}))
        system_prompt = cfg.system_prompt + UNEDITABLE_SYSTEM_PROMPT

        # Trim conversation history to prevent context overflow
        trimmed_messages = trim_messages(
            state["messages"],
            max_tokens=10000,
            strategy="last",
            token_counter=len,
        )

        messages = [SystemMessage(content=system_prompt)] + trimmed_messages
        response = await model_with_tools.ainvoke(messages, config)
        return {"messages": [response]}

    # Tools node ìƒì„±
    tools_node = ToolNode(tools) if tools else None

    # StateGraph ë¹Œë“œ
    workflow = StateGraph(AgentState, config_schema=GraphConfigPydantic)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("agent", agent_node)
    if tools_node:
        workflow.add_node("tools", tools_node)

    # ì—£ì§€ ì¶”ê°€
    workflow.add_edge(START, "agent")

    if tools_node:
        workflow.add_conditional_edges(
            "agent",
            should_continue,
            {
                "tools": "tools",
                END: END,
            },
        )
        workflow.add_edge("tools", "agent")
    else:
        workflow.add_edge("agent", END)

    # ì»´íŒŒì¼ ë° ë°˜í™˜
    return workflow.compile()
```

**ì´ ì¤„ ìˆ˜:** ~60 lines
**ì»¤ìŠ¤í„°ë§ˆì´ì§•:** ë¬´ì œí•œ
**ì œì–´:** ì™„ì „

---

## ğŸ¯ ìš”ì•½

### âœ… ì™„ë£Œí•œ ê²ƒ

1. **Import ì¶”ê°€**: StateGraph ë° trim_messages ëª¨ë“ˆ
2. **AgentState ì •ì˜**: ê·¸ë˜í”„ ìƒíƒœ í´ë˜ìŠ¤
3. **should_continue í•¨ìˆ˜**: ì¡°ê±´ë¶€ ë¼ìš°íŒ…
4. **StateGraph êµ¬í˜„**: ì™„ì „í•œ ReAct íŒ¨í„´
5. **ë©”ì‹œì§€ íŠ¸ë¦¬ë°**: ì»¨í…ìŠ¤íŠ¸ ì˜¤ë²„í”Œë¡œìš° ë°©ì§€ ë° ë¹„ìš© ìµœì í™”
6. **create_react_agent ì œê±°**: ê¸°ì¡´ ì½”ë“œ êµì²´

### ğŸ’ª ì´ì œ í•  ìˆ˜ ìˆëŠ” ê²ƒ

- âœ… ë…¸ë“œ ì¶”ê°€ (ê²€ì¦, ë¡œê¹…, í•„í„°ë§)
- âœ… State í™•ì¥ (metrics, context)
- âœ… ë³µì¡í•œ ë¼ìš°íŒ…
- âœ… ë””ë²„ê¹… ë° ëª¨ë‹ˆí„°ë§
- âœ… ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ

### ğŸš€ ë‹¤ìŒ ë„ì „

**ì¦‰ì‹œ ì‹œë„í•´ë³¼ ê²ƒ:**
1. ë¡œê¹… ë…¸ë“œ ì¶”ê°€
2. ì‘ë‹µ ì‹œê°„ ì¸¡ì •
3. ì»¤ìŠ¤í…€ ê²€ì¦ ë¡œì§

**ì¥ê¸° ëª©í‘œ:**
1. Multi-agent í˜‘ì—…
2. Human-in-the-loop
3. í”„ë¡œë•ì…˜ ë°°í¬

---

## ğŸ“ ë„ì›€ì´ í•„ìš”í•˜ë©´?

**ë¬¸ì œ ë°œìƒ ì‹œ:**
1. ì˜¤ë¥˜ ë©”ì‹œì§€ ì „ì²´ ë³µì‚¬
2. ê´€ë ¨ ì½”ë“œ ìŠ¤ë‹ˆí« ì¤€ë¹„
3. ì˜ˆìƒ ë™ì‘ vs ì‹¤ì œ ë™ì‘ ì„¤ëª…
4. LangGraph ê³µì‹ ë¬¸ì„œ ê²€ìƒ‰

**ì¶”ê°€ í•™ìŠµ:**
- [LangGraph íŠœí† ë¦¬ì–¼](https://langchain-ai.github.io/langgraph/tutorials/)
- [LangChain ì»¤ë®¤ë‹ˆí‹°](https://discord.gg/langchain)
- [GitHub Issues](https://github.com/langchain-ai/langgraph/issues)

---

**ì‘ì„±ì¼**: 2025-01-13
**ë²„ì „**: 1.0
**ëŒ€ìƒ í”„ë¡œì íŠ¸**: OAP-MCP (Open Agent Platform)
**ë‚œì´ë„**: ì¤‘ê¸‰ (ì‹ ì… ê°œë°œìë„ ë”°ë¼í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€)

---

ì´ ê°€ì´ë“œë¥¼ ì™„ë£Œí•˜ì…¨ë‹¤ë©´ ì¶•í•˜í•©ë‹ˆë‹¤! ğŸ‰
ì´ì œ LangGraphì˜ í•µì‹¬ ê°œë…ì„ ì´í•´í•˜ê³  ì»¤ìŠ¤í…€ ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!
